```
conda activate pt1.4
git pull origin master
nohup python main.py --batch-size 32 >new 2>&1 &
nohup python main.py --batch-size 32 --pretrain --res >new 2>&1 &
```

除以mask

## 5.16

mat，不行

res，f1：26

label的mean和图片加loss



## 5.15

改进了边的权重，本来是每个cd里边的权重都除以最大值，现在是每个label除以每个label的sum，不行

改进f1统计，f1：24

cd加loss，不行

改了mask，不行

最后再加一个图，不行

用上了rnn输出，不行



## 5.14

给根据cd给label加了mask，为了方便实验先用alex替换resnet，f1：16

对图中边的权重进行了修改，对图结点进行了改进，f1：22



## 5.13

代码基本改好了，试了一下不同的loss函数，但是效果都不好，用的softmax+bce，f1最多到10左右

现在在可视化数据，觉得300+个标签直接分类不行，想先用树或者knn分个大类，再分大类里的小类



## 5.12

理解错题目了，开始自暴自弃，Multi-Label Image Recognition with Graph Convolutional Networks，以这篇论文为基础开始改进

看了看这篇论文和代码在干什么

准备一下代码需要的资料（emb，图结构等

还在调代码



## 5.11

_发现理解错题目了，下面说的都是胡话_

对网络结构改进：

* 过拟合比较严重，加了bn：效果拔群
* 用了个efficientnet，但是效果好像并不好，还是先用alex吧，这个之后随缘练个丹

对loss改进：

* 发现了之前f1的计算有问题，重新改了一下
* 只用交叉熵：0.6779，交叉熵+0.25×f1:0.6567，效果不好，先放弃f1
* 用了余弦退火schedule: 0.6855， T=5，lr=1e-4
* 

数据增强：

* 统计了一下预测的差的图片，总结了一下他们的特点
* ('101002', 建筑比较大), ('20030', 建筑小后面有山), ('152042', 植物大背景颜色深),  ('147066', 背景比较鲜艳), ('384052', 人物大背景奇怪), ('46066', 背景深物体大), ('144018', 物体大), ('22013', 角度处于侧面), ('171064', ), ('142078', 建筑很大), ('120025', 背景不一样), ('296002', 22), ('121073', 22), ('22014', 22), ('121015', 22), ('17018', 22), ('121090', 22), ('142021', 22), ('140057', 22)
* 根据总结出的特点，加了一下的数据增强
* × norm： 0.6801（迷惑
* √ random resize crop： 0.6921，但是训练时间很长
* √ horizontal flip： 0.6898
* × color jitter



## 5.10

* 先撸了一个简单的模型，和alexnet差不多，没有用到label信息，打算先研究一下数据集里图片的特征吧

对loss改进：

* 先用了交叉熵，f1有50（过拟合还挺多的，之后加个bn看看

* 后来把loss改成了自己写的f1 loss，发现效果非常差。。。

* 同时用f1和交叉熵loss，效果和只用交叉熵差不多
* 想了想发现现在写的f1loss里，p和r是一样的，就相当于最大化p，只不过是用除法，而crossentropy是用加法最大化，还在改。。。



对transform改进：

* 加了随机翻转，five crop等，还在测试中